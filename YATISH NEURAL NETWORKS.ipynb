{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Assuming 10 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # For 10 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.SimpleRNN(50, activation='relu', input_shape=(timesteps, input_dim)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Long Short-Term Memory (LSTM) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.LSTM(100, activation='relu', input_shape=(timesteps, input_dim)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.GRU(100, activation='relu', input_shape=(timesteps, input_dim)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_img = tf.keras.layers.Input(shape=(784,))\n",
    "encoded = tf.keras.layers.Dense(64, activation='relu')(input_img)\n",
    "decoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = tf.keras.models.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# VAE typically requires more custom code, so here is a simplified setup\n",
    "latent_dim = 2\n",
    "\n",
    "# Encoder\n",
    "inputs = tf.keras.Input(shape=(784,))\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(inputs)\n",
    "z_mean = tf.keras.layers.Dense(latent_dim)(x)\n",
    "z_log_var = tf.keras.layers.Dense(latent_dim)(x)\n",
    "\n",
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + tf.keras.backend.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tf.keras.Input(shape=(latent_dim,))\n",
    "x_decoded = tf.keras.layers.Dense(256, activation='relu')(decoder_input)\n",
    "outputs = tf.keras.layers.Dense(784, activation='sigmoid')(x_decoded)\n",
    "\n",
    "encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "decoder = tf.keras.Model(decoder_input, outputs, name=\"decoder\")\n",
    "\n",
    "vae = tf.keras.Model(inputs, decoder(encoder(inputs)[2]))\n",
    "vae.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "vae.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = ResNet50(weights=None, input_shape=(224, 224, 3), classes=10)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Inception Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "model = InceptionV3(weights=None, input_shape=(299, 299, 3), classes=10)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "generator = Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=100),\n",
    "    tf.keras.layers.Dense(784, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Discriminator\n",
    "discriminator = Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "discriminator.trainable = False\n",
    "\n",
    "# GAN\n",
    "gan_input = tf.keras.Input(shape=(100,))\n",
    "generated_image = generator(gan_input)\n",
    "gan_output = discriminator(generated_image)\n",
    "\n",
    "gan = tf.keras.Model(gan_input, gan_output)\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "gan.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a code for splitting,training,Validation and test sets of Datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = range(1000)\n",
    "y = range(1000)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement custom activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_activation(x):\n",
    "    return K.sigmoid(x) * x\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(100,), activation=custom_activation),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a single LSTM cell from scratch. Create a forward pass for an LSTM network and test it on a simple sequential data task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LSTMCell:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.Wf = np.random.randn(hidden_size, input_size + hidden_size)\n",
    "        self.Wi = np.random.randn(hidden_size, input_size + hidden_size)\n",
    "        self.Wc = np.random.randn(hidden_size, input_size + hidden_size)\n",
    "        self.Wo = np.random.randn(hidden_size, input_size + hidden_size)\n",
    "\n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "        self.bi = np.zeros((hidden_size, 1))\n",
    "        self.bc = np.zeros((hidden_size, 1))\n",
    "        self.bo = np.zeros((hidden_size, 1))\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        combined = np.concatenate((h_prev, x), axis=1).T  # Transpose combined to (input_size + hidden_size, batch_size)\n",
    "        \n",
    "        forget_gate = self.sigmoid(np.dot(self.Wf, combined) + self.bf)\n",
    "        input_gate = self.sigmoid(np.dot(self.Wi, combined) + self.bi)\n",
    "        candidate_memory = np.tanh(np.dot(self.Wc, combined) + self.bc)\n",
    "        output_gate = self.sigmoid(np.dot(self.Wo, combined) + self.bo)\n",
    "        \n",
    "        c_next = forget_gate * c_prev.T + input_gate * candidate_memory\n",
    "        h_next = output_gate * np.tanh(c_next)\n",
    "        \n",
    "        return h_next.T, c_next.T  # Return h_next and c_next in their original shapes\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "input_size, hidden_size = 4, 8\n",
    "lstm_cell = LSTMCell(input_size, hidden_size)\n",
    "x = np.random.randn(1, input_size)  # Shape (1, input_size)\n",
    "h_prev = np.zeros((1, hidden_size))  # Shape (1, hidden_size)\n",
    "c_prev = np.zeros((1, hidden_size))  # Shape (1, hidden_size)\n",
    "\n",
    "h_next, c_next = lstm_cell.forward(x, h_prev, c_prev)\n",
    "print(h_next, c_next)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    resnet,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/path/to/your/dataset',  \n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    'C:/path/to/your/dataset',  # Replace this with your dataset path\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model.fit(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to implement the sequential model using CNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
